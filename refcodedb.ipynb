{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPQ0Whoo5OhLSaUCBd6cOw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devdaveddev/DebateBOT/blob/main/refcodedb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import wordnet\n",
        "from transformers import pipeline, BertForSequenceClassification, BertTokenizer, T5ForConditionalGeneration, T5Tokenizer\n",
        "from textblob import TextBlob\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Initialize NLP models\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Load BERT model for sentiment analysis\n",
        "bert_model = BertForSequenceClassification.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "def fetch_data(url, headers=None):\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    return {}\n",
        "\n",
        "def fetch_wikipedia_data(topic):\n",
        "    url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{topic}\"\n",
        "    return fetch_data(url).get(\"extract\", \"No information found.\")\n",
        "\n",
        "def fetch_stackexchange_data(topic):\n",
        "    url = f\"https://api.stackexchange.com/2.3/search?order=desc&sort=relevance&intitle={topic}&site=history\"\n",
        "    response = fetch_data(url)\n",
        "    return [item[\"title\"] for item in response.get(\"items\", [])[:5]]\n",
        "\n",
        "def fetch_reddit_data(topic):\n",
        "    url = f\"https://www.reddit.com/r/debaterelated/search.json?q={topic}&restrict_sr=1\"\n",
        "    headers = {'User-Agent': 'debate-bot'}\n",
        "    response = fetch_data(url, headers)\n",
        "    return [post[\"data\"][\"title\"] for post in response.get(\"data\", {}).get(\"children\", [])[:5]]\n",
        "\n",
        "def fetch_philosopher_data():\n",
        "    philosophers = [\"Socrates\", \"Plato\", \"Nietzsche\", \"Franz Kafka\", \"Neil deGrasse Tyson\", \"Alex O'Connor\"]\n",
        "    return {philosopher: fetch_wikipedia_data(philosopher) for philosopher in philosophers}\n",
        "\n",
        "def bert_sentiment_analysis(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "    outputs = bert_model(**inputs)\n",
        "    scores = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    sentiment_score = torch.argmax(scores).item()\n",
        "    return sentiment_score\n",
        "\n",
        "# Transformer for Philosophical Style Adaptation\n",
        "style_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "style_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "def adapt_style(text, philosopher):\n",
        "    input_text = f\"Rewrite as {philosopher}: {text}\"\n",
        "    inputs = style_tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "    outputs = style_model.generate(**inputs)\n",
        "    return style_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Lexical Substitution for Philosophical Language Enhancement\n",
        "def lexical_substitution(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    new_text = []\n",
        "    for word in words:\n",
        "        synonyms = wordnet.synsets(word)\n",
        "        if synonyms:\n",
        "            new_text.append(synonyms[0].lemmas()[0].name())\n",
        "        else:\n",
        "            new_text.append(word)\n",
        "    return ' '.join(new_text)\n",
        "\n",
        "# ANN Model for Learning Debate Styles\n",
        "class DebateANN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(DebateANN, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.output_layer = tf.keras.layers.Dense(5, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        x = self.dense2(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "ann_model = DebateANN()\n",
        "ann_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# TensorFlow Reinforcement Learning Model with LSTM\n",
        "class DebateRLModel:\n",
        "    def __init__(self):\n",
        "        self.lstm_model = tf.keras.Sequential([\n",
        "            tf.keras.layers.LSTM(32, activation='relu', input_shape=(None, 5)),\n",
        "            tf.keras.layers.Dense(32, activation='relu'),\n",
        "            tf.keras.layers.Dense(5, activation='linear')\n",
        "        ])\n",
        "        self.lstm_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "        self.rl_model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(16, activation='relu', input_shape=(5,)),\n",
        "            tf.keras.layers.Dense(16, activation='relu'),\n",
        "            tf.keras.layers.Dense(5, activation='linear')\n",
        "        ])\n",
        "        self.rl_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "        self.memory = []\n",
        "\n",
        "    def train(self):\n",
        "        if len(self.memory) > 100:\n",
        "            batch = random.sample(self.memory, 100)\n",
        "            X, y = zip(*batch)\n",
        "            self.rl_model.fit(np.array(X), np.array(y), epochs=5, verbose=0)\n",
        "            self.lstm_model.fit(np.array(X), np.array(y), epochs=5, verbose=0)\n",
        "\n",
        "    def predict(self, X):\n",
        "        rl_prediction = self.rl_model.predict(np.array([X]))[0]\n",
        "        lstm_prediction = self.lstm_model.predict(np.array([X]))[0]\n",
        "        ann_prediction = ann_model.predict(np.array([X]))[0]\n",
        "        combined_prediction = (rl_prediction + lstm_prediction + ann_prediction) / 3\n",
        "        return combined_prediction\n",
        "\n",
        "    def remember(self, state, reward):\n",
        "        self.memory.append((state, reward))\n",
        "        if len(self.memory) > 1000:\n",
        "            self.memory.pop(0)\n",
        "\n",
        "rl_model = DebateRLModel()\n",
        "\n",
        "def interactive_debate():\n",
        "    print(\"Welcome to the AI Debate System!\")\n",
        "    mode = input(\"Choose mode: 1 for Philosophical Debate, 2 for Independent AI Response: \")\n",
        "    if mode == \"1\":\n",
        "        philosophers = [\"Socrates\", \"Plato\", \"Aristotle\", \"Nietzsche\", \"Descartes\"]\n",
        "        print(\"Choose a philosopher:\")\n",
        "        for i, name in enumerate(philosophers):\n",
        "            print(f\"{i+1}. {name}\")\n",
        "        choice = int(input(\"Enter your choice: \")) - 1\n",
        "        selected_philosopher = philosophers[choice]\n",
        "        print(f\"You are debating with {selected_philosopher}. Enter your argument:\")\n"
      ],
      "metadata": {
        "id": "y6WHt5MhtFM0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}